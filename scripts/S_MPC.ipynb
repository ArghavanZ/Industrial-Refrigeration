{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4888426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "ROOT = os.path.abspath(\"..\")  # or specific path\n",
    "sys.path.append(os.path.join(ROOT, \"src\"))\n",
    "import yaml\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym_env.ref_env import Ref, make_env\n",
    "from helpers import helper as h\n",
    "from helpers import device as d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3796d",
   "metadata": {},
   "source": [
    "### For now, just for C05!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e8409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_n = 2\n",
    "c_room = 40500000\n",
    "Q_dist = 33700\n",
    "min_temp = -16\n",
    "max_temp = -22\n",
    "T_suction = -27\n",
    "Q_rated = 600000\n",
    "W_rated = 100000\n",
    "T_rated = -25\n",
    "Q_max = 2000*(T_suction - T_rated)/30 + Q_rated\n",
    "W_max = -70 *(T_suction - T_rated)**2 + W_rated\n",
    "high_penalty = 1\n",
    "low_penalty = 0.5\n",
    "delta_t = 60\n",
    "bevap = 22900\n",
    "e_p = 1.0e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92ad9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43fc4722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0 0]\n",
      "[1]\n",
      "[1 0]\n",
      "[2]\n",
      "[0 1]\n",
      "[3]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "T_room = np.array([-20.0, -21.0])\n",
    "best_action = None\n",
    "best_cost = float('inf')\n",
    "    \n",
    "# Generate all possible action sequences for the lookahead horizon\n",
    "for action_seq in range(4**1):\n",
    "    actions = [(action_seq >> (2 * i)) & 3 for i in range(1)]\n",
    "    T_sim = T_room.copy()\n",
    "    total_cost = 0\n",
    "    print(actions)\n",
    "    action_array = np.array([1 if (actions[0] >> i) & 1 else 0 for i in range(room_n)])\n",
    "    print(action_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f808f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MPC(T_room , lookahead):\n",
    "    \"\"\"\n",
    "    Model Predictive Control for a refrigeration system with multiple rooms.\n",
    "    \n",
    "    Parameters:\n",
    "    T_room (np.array): Current temperatures of the rooms.\n",
    "    lookahead (int): Number of future time steps to consider in the optimization.\n",
    "    \n",
    "    Returns:\n",
    "    int: Optimal action (0 or 1) for the current time step.\n",
    "    \"\"\"\n",
    "    best_action = None\n",
    "    best_cost = float('inf')\n",
    "    \n",
    "    # Generate all possible action sequences for the lookahead horizon\n",
    "    for action_seq in range(4**lookahead):\n",
    "        actions = [(action_seq >> (2 * i)) & 3 for i in range(lookahead)]\n",
    "        T_sim = T_room.copy()\n",
    "        total_cost = 0\n",
    "        print(actions)\n",
    "\n",
    "        \n",
    "        for action in actions:\n",
    "            # first map 0 - 3 to array of 0s and 1s\n",
    "            action_array = np.array([1 if (action >> i) & 1 else 0 for i in range(room_n)])\n",
    "            # Calculate Q_evap based on the current action\n",
    "            Q_evap = bevap * (T_sim - T_suction*np.ones_like(T_sim)) * action_array\n",
    "            Q_evap = np.maximum(Q_evap, 0)\n",
    "            Q_total = np.minimum(np.sum(Q_evap), Q_max)\n",
    "            Q_evap = Q_evap * (Q_total / (np.sum(Q_evap)))  # Scale Q_evap to not exceed Q_max\n",
    "            W = W_max * ((Q_total / Q_max)*0.61 + 0.39*(Q_total>0))\n",
    "            C_cost = W * e_p * (delta_t)  # Cost in dollars for the time step\n",
    "            step_cost = C_cost\n",
    "            # Update room temperatures\n",
    "            T_sim += (delta_t / c_room) * (Q_dist - Q_evap)\n",
    "\n",
    "            \n",
    "            # Calculate cost\n",
    "            \n",
    "            high_violation = np.maximum(0,  T_sim - max_temp*np.ones_like(T_sim))\n",
    "            low_violation = np.maximum(0,  min_temp*np.ones_like(T_sim) - T_sim)\n",
    "            step_cost += (high_penalty * np.sum(high_violation) + low_penalty * np.sum(low_violation) )* delta_t\n",
    "            total_cost += step_cost\n",
    "            \n",
    "        # Update best action if current sequence has lower cost\n",
    "        if total_cost < best_cost:\n",
    "            best_cost = total_cost\n",
    "            best_action = actions[0]\n",
    "    \n",
    "    return best_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7dda79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_path = 'env_config/C04.yaml'  # Default path for environment configuration\n",
    "with open(f\"{ROOT}/{C_path}\", 'r') as f:\n",
    "        env_cfg = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "params = env_cfg.copy()\n",
    "timelimit = 1440 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3a8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ep = 1\n",
    "n_seeds = 1\n",
    "reward = np.zeros (shape = (n_seeds, n_ep , timelimit))\n",
    "for n in range(n_seeds):\n",
    "    env = Monitor(gym.wrappers.TimeLimit(Ref(params=params), max_episode_steps=timelimit))\n",
    "    for ep in range(n_ep):\n",
    "        t = 0\n",
    "        obs, info = env.reset(seed=n*50+ep)\n",
    "        terminated, truncated = False, False\n",
    "        T_room = obs[\"room_temperatures\"]\n",
    "        while not (terminated or truncated):\n",
    "            t+=1\n",
    "            action = MPC(T_room, lookahead)\n",
    "            obs, reward[n, ep, t-1], terminated, truncated, info = env.step(action)\n",
    "            T_room = obs[\"room_temperatures\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
